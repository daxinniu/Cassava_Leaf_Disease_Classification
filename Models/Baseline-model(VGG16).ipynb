{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"baseline-model.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_JrtdqV-jVJf"},"source":["# Baseline Model (VGG16)"]},{"cell_type":"code","metadata":{"id":"H3mqlf8pgzzf"},"source":["import numpy as np \n","import pandas as pd \n","import time\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import shutil, os\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D, Input\n","import json\n","from scipy import stats\n","from tensorflow.keras import Model, Sequential\n","from tensorflow.keras.regularizers import l1\n","from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay\n","from tensorflow.keras.applications import VGG16\n","from matplotlib import pyplot as plt\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from PIL import Image, ImageStat\n","from skimage import io, color"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W657CTZOiFhJ","executionInfo":{"elapsed":17207,"status":"ok","timestamp":1623285294988,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"},"user_tz":240},"outputId":"d31da864-038a-47cf-cf83-d4fa33028ac5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZS-ysKLhjf3w"},"source":["## Load data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DgYIGiU0h9eY","executionInfo":{"elapsed":1267,"status":"ok","timestamp":1623285297750,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"},"user_tz":240},"outputId":"7a00a206-ce8f-4da6-cc1d-ada7c0e4ae7d"},"source":["# Loading the training data\n","train_raw = pd.read_csv('train.csv', encoding='utf_8_sig', engine='python')\n","print(train_raw.head())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["         image_id  label\n","0  1000015157.jpg      0\n","1  1000201771.jpg      3\n","2   100042118.jpg      1\n","3  1000723321.jpg      1\n","4  1000812911.jpg      3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KALHG8qTjii4"},"source":["## Train-test split"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NiUvdUnUgzzg","executionInfo":{"elapsed":127454,"status":"ok","timestamp":1623285425200,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"},"user_tz":240},"outputId":"4a41ba8e-cb7e-4c45-90c0-c6d5b3484bea"},"source":["# Set hyper-parameter\n","_batch_size = 32\n","_image_width = 160\n","_image_height = 120\n","\n","# Train test split\n","train_raw['label'] = train_raw['label'].astype(str)\n","x_train, x_test, y_train, y_test = train_test_split(train_raw['image_id'], train_raw['label'], test_size=0.2)\n","xy_train = pd.DataFrame({'x': x_train, 'y': y_train})\n","xy_test = pd.DataFrame({'x': x_test, 'y': y_test})\n","\n","# Image augmentation\n","train_data_gen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2\n",")\n","\n","# Get train valid data\n","train_generator = train_data_gen.flow_from_dataframe(dataframe=train_raw,\n","                                                     directory='train_images',\n","                                                     subset='training',\n","                                                     x_col='image_id',\n","                                                     y_col='label',\n","                                                     shuffle=True,\n","                                                     target_size=(160, 120),\n","                                                     batch_size=32,\n","                                                     class_mode='categorical')\n","\n","\n","validation_generator = train_data_gen.flow_from_dataframe(dataframe=train_raw,\n","                                                          directory='train_images',\n","                                                          subset='validation',\n","                                                          x_col='image_id',\n","                                                          y_col='label',\n","                                                          shuffle=True,\n","                                                          target_size=(160, 120),\n","                                                          batch_size=32,\n","                                                          class_mode='categorical')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 17118 validated image filenames belonging to 5 classes.\n","Found 4279 validated image filenames belonging to 5 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4EZtdkP_VX36"},"source":["## Baseline model (VGG16)"]},{"cell_type":"code","metadata":{"id":"iHxDPZSwjSJi"},"source":["def tb_callback(exp_name):\n","    return TensorBoard(log_dir=_log_dir + exp_name, profile_batch=0, histogram_freq=1)\n","\n","\n","def build_baseline_vgg():\n","    input_shape = (160, 120, 3)\n","    baseline_model = VGG16(weights=None, include_top=False, input_shape=input_shape)\n","    x = baseline_model.output\n","    x = Flatten()(x)\n","    x = Dense(512, activation='relu')(x)\n","    x = Dropout(rate=0.25)(x)\n","\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(rate=0.25)(x)\n","\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(rate=0.25)(x)\n","\n","    predictions = Dense(5, activation='softmax')(x)\n","    model = Model(inputs=baseline_model.input, outputs=predictions)\n","    model.compile(optimizer=_opt,\n","                  loss=_loss,\n","                  metrics=_metrics)\n","    \n","    print(model.summary())\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"VqRXr9eUgzzh","outputId":"911d2400-5230-4bd8-e875-f004c14c6134"},"source":["_shuffle = True\n","\n","_log_dir = 'baseline_model'\n","_seed = 27\n","_learning_rate = 0.001\n","_schedule = ExponentialDecay(_learning_rate, decay_steps=10_0000, decay_rate=0.96)\n","_opt = Adam(learning_rate=_schedule)\n","_es = EarlyStopping(monitor='val_accuracy', patience=20)\n","_tb = tb_callback('Baseline_model_1')\n","_callbacks = [_es, _tb]\n","_metrics = ['accuracy']\n","_loss = 'categorical_crossentropy'\n","_epochs = 4\n","\n","\n","baseline_model1 = build_baseline_vgg()\n","baseline_model1_hist = baseline_model1.fit(train_generator,\n","                                           epochs=_epochs,\n","                                           validation_data=validation_generator,\n","                                           callbacks=_callbacks,\n","                                           shuffle=_shuffle)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 160, 120, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 160, 120, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 160, 120, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 80, 60, 64)        0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 80, 60, 128)       73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 80, 60, 128)       147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 40, 30, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 40, 30, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 40, 30, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 40, 30, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 20, 15, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 20, 15, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 20, 15, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 20, 15, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 10, 7, 512)        0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 10, 7, 512)        2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 10, 7, 512)        2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 10, 7, 512)        2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 5, 3, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 7680)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               3932672   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 5)                 645       \n","=================================================================\n","Total params: 18,812,229\n","Trainable params: 18,812,229\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/4\n","472/535 [=========================>....] - ETA: 23:56 - loss: 1.1564 - accuracy: 0.6165"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Uu2Jg2gSPT_8"},"source":["## Save Model"]},{"cell_type":"code","metadata":{"id":"xA4spYHagzzi"},"source":["# save model\n","from keras.models import load_model\n","def save_model(model, name):\n","  model_name = '{}.h5'.format(name)\n","  save_dir = os.path.join(os.getcwd(), 'saved_models')\n","  \n","  # Save model and weights\n","  if not os.path.isdir(save_dir):\n","      os.makedirs(save_dir)\n","  model_path = os.path.join(save_dir, model_name)\n","  model.save(model_path)\n","  print('Saved trained model at %s ' % model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DU4JMouggzzi"},"source":["save_model(baseline_model1, 'baseline_model1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Q02-ffmgzzi"},"source":["# Make sure to save the model you trained to /kaggle/working! \n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import smart_resize\n","## Load model. Use \"load_weights\" if you only save your model weights.\n","model = keras.models.load_model(\"./saved_models/baseline_model1.h5\")\n","\n","preds = []\n","sample_sub = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/sample_submission.csv')\n","\n","sample_sub.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2JRlqvYHgzzj"},"source":["for image in sample_sub.image_id:\n","    img = keras.preprocessing.image.load_img('test_images' + image)\n","    #\n","    # Preprocess image here (rescale, etc. - you might need to use parameters you determined during training)\n","    #\n","    img = img_to_array(img)\n","    img = smart_resize(img, (160, 120))\n","    img = tf.reshape(img, (-1, 160, 120, 3))\n","    \n","    # Now apply your model and save your prediction:\n","    prediction = model.predict(img)\n","    \n","    preds.append(np.argmax(prediction))\n","\n","my_submission = pd.DataFrame({'image_id': sample_sub.image_id, 'label': preds})\n","my_submission.to_csv('/kaggle/working/submission.csv', index=False)"],"execution_count":null,"outputs":[]}]}